
# Job Market Analysis Tool â€“ Big Data (Solo Starter)

This repo is a clean, minimal starter that matches the original team plan but streamlined for a **solo** build. It gives you a runnable FastAPI service, ingestion stubs, ETL scaffolding, and a place to add modelsâ€”not heavy infra yet.

## Quickstart (Local)

1) **Python 3.11** recommended.
```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

2) **Run the API** (for now it just has a health check and a stub salary endpoint).
```bash
make api
# visit http://127.0.0.1:8000/docs
```

3) **Try a tiny sample ingest** (one day of GH Archive, one BLS table).
```bash
python src/ingest/download_gharchive.py --date 2024-01-01
python src/ingest/download_bls.py --series oe
```

> Weâ€™re intentionally starting small. Once the skeleton works endâ€‘toâ€‘end, weâ€™ll scale to the full 20GB+ sources and add Spark/Delta/Airflow.

---

## Project Structure

```
job-market-analysis/
â”œâ”€â”€ ðŸ“ data/                           # Data Lake Architecture (129.68 GB)
â”‚   â”œâ”€â”€ ðŸ“ raw/                        # Original data sources
â”‚   â”‚   â”œâ”€â”€ ðŸ“ github/                 # GitHub Archive data (123.43 GB)
â”‚   â”‚   â”œâ”€â”€ ðŸ“ kaggle/                 # Job market datasets (2.23 GB)
â”‚   â”‚   â”œâ”€â”€ ðŸ“ stackoverflow/          # Developer surveys (0.88 GB)
â”‚   â”‚   â””â”€â”€ ðŸ“ bls/                    # BLS employment data (0.002 GB)
â”‚   â”œâ”€â”€ ðŸ“ bronze/                     # Cleaned and standardized data (3.14 GB)
â”‚   â”œâ”€â”€ ðŸ“ silver/                     # Unified datasets (0.004 GB)
â”‚   â””â”€â”€ ðŸ“ gold/                       # ML-ready data (0 GB)
â”‚
â”œâ”€â”€ ðŸ“ src/                            # Source Code
â”‚   â”œâ”€â”€ ðŸ“ api/                        # FastAPI Application
â”‚   â”‚   â””â”€â”€ ðŸ“„ app.py                  # Main API server
â”‚   â”œâ”€â”€ ðŸ“ common/                     # Shared Utilities
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ logs.py                 # Logging configuration
â”‚   â”‚   â””â”€â”€ ðŸ“„ paths.py                # Path management
â”‚   â”œâ”€â”€ ðŸ“ etl/                        # ETL Pipeline
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ bronze_to_silver.py     # Bronze to Silver processing
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ build_unified_postings.py # Unified job postings
â”‚   â”‚   â””â”€â”€ ðŸ“„ silver_to_gold.py       # Silver to Gold processing
â”‚   â”œâ”€â”€ ðŸ“ ingest/                     # Data Ingestion
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ comprehensive_data_processor.py # Main data processor
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ download_gharchive.py   # GitHub Archive downloader
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ download_stackoverflow.py # StackOverflow downloader
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ download_bls.py         # BLS data downloader
â”‚   â”‚   â””â”€â”€ ðŸ“„ massive_github_collector.py # Large-scale GitHub collection
â”‚   â”œâ”€â”€ ðŸ“ ml/                         # Machine Learning
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ salary_prediction_model.py # XGBoost salary model
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ skill_forecasting.py    # Skills trend analysis
â”‚   â”‚   â””â”€â”€ ðŸ“„ train_salary_model.py   # Model training pipeline
â”‚   â”œâ”€â”€ ðŸ“ spark/                      # Apache Spark Processing
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ etl_pipeline.py         # Spark ETL pipeline
â”‚   â”‚   â””â”€â”€ ðŸ“„ simple_etl.py           # Simple Spark processing
â”‚   â”œâ”€â”€ ðŸ“ streaming/                  # Real-time Streaming
â”‚   â”‚   â””â”€â”€ ðŸ“„ kafka_demo.py           # Apache Kafka streaming demo
â”‚   â”œâ”€â”€ ðŸ“„ app_streamlit.py            # Main Streamlit dashboard
â”‚   â””â”€â”€ ðŸ“„ app_streamlit_simple.py     # Simple Streamlit interface
â”‚
â”œâ”€â”€ ðŸ“ dags/                           # Apache Airflow DAGs
â”‚   â”œâ”€â”€ ðŸ“„ job_market_airflow_dag.py   # Main Airflow workflow
â”‚   â””â”€â”€ ðŸ“„ job_market_dag.py           # Job market processing DAG
â”‚
â”œâ”€â”€ ðŸ“ notebooks/                      # Jupyter Notebooks
â”‚   â””â”€â”€ ðŸ“„ EDA.ipynb                   # Exploratory Data Analysis
â”‚
â”œâ”€â”€ ðŸ“ reports/                        # Analysis Reports
â”‚   â””â”€â”€ ðŸ“„ job_market_analysis.md      # Comprehensive analysis report
â”‚
â”œâ”€â”€ ðŸ“ models/                         # Trained Models
â”‚   â””â”€â”€ ðŸ“„ salary_prediction_model.pkl # XGBoost salary prediction model
â”‚
â”œâ”€â”€ ðŸ“ mlruns/                         # MLflow Experiment Tracking
â”‚   â””â”€â”€ ðŸ“ [experiment_runs]/          # ML experiment runs and artifacts
â”‚
â”œâ”€â”€ ðŸ“„ fast_api.py                     # FastAPI server launcher
â”œâ”€â”€ ðŸ“„ smart_career_api.py             # Career insights API
â”œâ”€â”€ ðŸ“„ optimized_streamlit.py          # Optimized Streamlit app
â”œâ”€â”€ ðŸ“„ simple_streamlit.py             # Simple Streamlit app
â”œâ”€â”€ ðŸ“„ demo_academic_presentation.py   # Academic presentation demo
â”œâ”€â”€ ðŸ“„ demo_all_tools_working.py       # Big Data tools demonstration
â”œâ”€â”€ ðŸ“„ requirements.txt                # Python dependencies
â”œâ”€â”€ ðŸ“„ requirements-dev.txt            # Development dependencies
â”œâ”€â”€ ðŸ“„ Makefile                        # Build automation
â”œâ”€â”€ ðŸ“„ start_apps.sh                   # Application startup script
â””â”€â”€ ðŸ“„ README.md                       # This file
```

## Key Features

### ðŸ—ï¸ **Data Lake Architecture**
- **Raw Layer**: 126.54 GB of original data from 4 sources
- **Bronze Layer**: 3.14 GB of cleaned and standardized data
- **Silver Layer**: Unified datasets across sources
- **Gold Layer**: ML-ready feature engineering

### ðŸš€ **Big Data Tools**
- **Apache Spark**: Distributed data processing
- **Delta Lake**: Versioned data storage
- **Apache Airflow**: Workflow orchestration
- **Apache Kafka**: Real-time streaming
- **MLflow**: ML experiment tracking

### ðŸ¤– **Machine Learning**
- **XGBoost**: Salary prediction model
- **Feature Engineering**: Automated pipeline
- **Model Serving**: FastAPI endpoints
- **Experiment Tracking**: MLflow integration

### ðŸŒ **API & Visualization**
- **FastAPI**: REST API with 5+ endpoints
- **Streamlit**: Interactive dashboards
- **Real-time Data**: Live GitHub activity
- **Predictive Analytics**: Salary predictions

---

## Solo Build Roadmap (Week 1â€“2)

- [ ] **Environment ready**: venv, requirements, `make api` runs, `/health` healthy
- [ ] **Sample ingest works**: pull 1 day GHArchive JSON, 1 BLS table to `data/raw`
- [ ] **Bronze â†’ Silver**: basic cleaner normalizes schema for GH/BLS
- [ ] **EDA notebook**: quick profiling + first plots
- [ ] **ML stub**: scaffold training for salary regression (no real model yet)
- [ ] **Streamlit stub**: tiny dashboard that can hit the API

Once this is stable, weâ€™ll add **Spark**, **Delta Lake**, and **Airflow** so you can scale up.

---

## Make Targets

```bash
make api         # run FastAPI (uvicorn)
make format      # format with black (optional if installed)
make test        # run tests (placeholder)
```

---

## Configuration

Use `.env` (local only) to store simple secrets/paths:

```
DATA_DIR=./data
BLS_BASE=https://download.bls.gov/pub/time.series
```

> For production, move secrets to a proper store (Keychain, cloud secret manager).

